{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required imports\n",
    "from sklearn.feature_extraction import text \n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import wordnet as wn\n",
    "import pandas as pd\n",
    "import random\n",
    "from nltk.classify import accuracy, NaiveBayesClassifier\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector is defined according to features identified \n",
    "# over the tfm document\n",
    "\n",
    "global_features = {}\n",
    "\n",
    "# origin type\n",
    "global_features['origin'] = []\n",
    "# joy\n",
    "global_features['origin'].append('pleasant')\n",
    "global_features['origin'].append('wellness')\n",
    "# sadness\n",
    "global_features['origin'].append('setback')\n",
    "# anger\n",
    "global_features['origin'].append('frustration')\n",
    "global_features['origin'].append('adversity')\n",
    "# fear\n",
    "global_features['origin'].append('danger')\n",
    "# surprise\n",
    "global_features['origin'].append('stimulus')\n",
    "global_features['origin'].append('unexpected')\n",
    "global_features['origin'].append('intensity')\n",
    "\n",
    "\n",
    "# effect type\n",
    "global_features['effect'] = []\n",
    "\n",
    "# consequence type\n",
    "global_features['consequence'] = []\n",
    "# joy\n",
    "global_features['consequence'].append('smile')\n",
    "global_features['consequence'].append('interaction')\n",
    "global_features['consequence'].append('creativity')\n",
    "# sadness\n",
    "global_features['consequence'].append('refusal')\n",
    "global_features['consequence'].append('misfortune')\n",
    "global_features['consequence'].append('weakness')\n",
    "# anger\n",
    "global_features['consequence'].append('destroy')\n",
    "global_features['consequence'].append('aggressiveness')\n",
    "global_features['consequence'].append('hostile')\n",
    "# fear\n",
    "global_features['consequence'].append('obsession')\n",
    "global_features['consequence'].append('panic')\n",
    "global_features['consequence'].append('phobia')\n",
    "global_features['consequence'].append('anxiety')\n",
    "# surprise\n",
    "global_features['consequence'].append('setback')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some common functions \n",
    "\n",
    "# used to avoid accessing the global features var directly\n",
    "def get_features():\n",
    "    return global_features\n",
    "\n",
    "# used to remove stopwords from a phrase\n",
    "def get_clean_phrase(phrase):\n",
    "    return ' '.join(word for (word) in phrase.split() if word not in text.ENGLISH_STOP_WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         phrase\n",
      "          count\n",
      "feeling        \n",
      "anger      2709\n",
      "fear       2373\n",
      "joy        6761\n",
      "sadness    5797\n",
      "surprise    719\n"
     ]
    }
   ],
   "source": [
    "# dataset is loaded into different dataframes\n",
    "df_test = pd.read_csv(\"data/test.txt\", sep=\";\", names=['phrase', 'feeling'])\n",
    "df_train = pd.read_csv(\"data/train.txt\", sep=\";\", names=['phrase', 'feeling'])\n",
    "df_val = pd.read_csv(\"data/val.txt\", sep=\";\", names=['phrase', 'feeling'])\n",
    "\n",
    "# dataframes are joined\n",
    "df = pd.concat([df_test, df_train, df_val])\n",
    "\n",
    "\n",
    "# remove \"love\" feeling as we do not have features for it\n",
    "data_without_love = df[df['feeling']!= 'love'] \n",
    "\n",
    "# we print the phrase count for each feeling\n",
    "print(data_without_love.groupby(['feeling']).agg(['count']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         phrase\n",
      "          count\n",
      "feeling        \n",
      "anger       720\n",
      "fear        720\n",
      "joy         720\n",
      "sadness     720\n",
      "surprise    719\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# since the min amount of phrases is 719 for one feeling\n",
    "# we create a subset to avoid overtraining\n",
    "# and by doing this, we balance the dataset\n",
    "data_filtered = pd.concat([data_without_love[data_without_love['feeling']== 'anger'].sample(720), \\\n",
    "                          data_without_love[data_without_love['feeling']== 'fear'].sample(720), \\\n",
    "                          data_without_love[data_without_love['feeling']== 'joy'].sample(720), \n",
    "                          data_without_love[data_without_love['feeling']== 'sadness'].sample(720),\n",
    "                          data_without_love[data_without_love['feeling']== 'surprise']])\n",
    "    \n",
    "#data_filtered = data_without_love\n",
    "print(data_filtered.groupby(['feeling']).agg(['count']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
